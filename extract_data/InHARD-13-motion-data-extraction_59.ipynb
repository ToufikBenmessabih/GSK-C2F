{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c18e8b83",
   "metadata": {},
   "source": [
    "# Get the motion data\n",
    "\n",
    "InHARD dataset contains motion data of operators executing assembly tasks. the motion data contains joint positions and joint rotations at each frame. \n",
    "\n",
    "Data is stored in BVH files including the hiarchy of the skeleton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ec2745c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nbr of joints: 59\n",
      "nbr of columns: 354\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the path to your BVH file\n",
    "bvh_file_path = \"./InHARD_13/Skeleton/P01_R01.bvh\"\n",
    "\n",
    "Joint = ['Hips',\n",
    "'RightUpLeg','RightLeg','RightFoot',\n",
    "'LeftUpLeg','LeftLeg','LeftFoot',\n",
    "'Spine','Spine1','Spine2','Spine3','Neck','Head',\n",
    "'RightShoulder','RightArm','RightForeArm','RightHand','RightHandThumb1','RightHandThumb2','RightHandThumb3',\n",
    "'RightInHandIndex','RightHandIndex1','RightHandIndex2','RightHandIndex3',\n",
    "'RightInHandMiddle','RightHandMiddle1','RightHandMiddle2','RightHandMiddle3',\n",
    "'RightInHandRing','RightHandRing1','RightHandRing2','RightHandRing3',\n",
    "'RightInHandPinky','RightHandPinky1','RightHandPinky2','RightHandPinky3',\n",
    "'LeftShoulder','LeftArm','LeftForeArm','LeftHand','LeftHandThumb1','LeftHandThumb2','LeftHandThumb3',\n",
    "'LeftInHandIndex','LeftHandIndex1','LeftHandIndex2','LeftHandIndex3',\n",
    "'LeftInHandMiddle','LeftHandMiddle1','LeftHandMiddle2','LeftHandMiddle3',\n",
    "'LeftInHandRing','LeftHandRing1','LeftHandRing2','LeftHandRing3',\n",
    "'LeftInHandPinky','LeftHandPinky1','LeftHandPinky2','LeftHandPinky3']\n",
    "\n",
    "print(\"nbr of joints:\", len(Joint))\n",
    "\n",
    "joints = []\n",
    "for joint in Joint:\n",
    "    joints.append(joint + '_xp')\n",
    "    joints.append(joint + '_yp')\n",
    "    joints.append(joint + '_zp')\n",
    "    joints.append(joint + '_yo')\n",
    "    joints.append(joint + '_xo')\n",
    "    joints.append(joint + '_zo')\n",
    "    \n",
    "print(\"nbr of columns:\", len(joints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "444142bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P01_R01\n",
      "P01_R02\n",
      "P01_R03\n",
      "P02_R01\n",
      "P02_R02\n",
      "P03_R01\n",
      "P03_R03\n",
      "P03_R04\n",
      "P04_R01\n",
      "P04_R02\n",
      "P05_R01\n",
      "P05_R02\n",
      "P05_R03\n",
      "P05_R04\n",
      "P06_R01\n",
      "P07_R01\n",
      "P07_R02\n",
      "P08_R01\n",
      "P08_R02\n",
      "P08_R03\n",
      "P08_R04\n",
      "P09_R01\n",
      "P09_R02\n",
      "P09_R03\n",
      "P10_R01\n",
      "P10_R02\n",
      "P10_R03\n",
      "P11_R01\n",
      "P11_R02\n",
      "P12_R01\n",
      "P12_R02\n",
      "P13_R02\n",
      "P14_R01\n",
      "P14_R02\n",
      "P15_R01\n",
      "P15_R02\n",
      "P16_R01\n",
      "P16_R02\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from itertools import islice\n",
    "\n",
    "directory_path = './InHARD_13/Skeleton'  # Replace with the actual path to your directory\n",
    "# Create a dictionary to store DataFrames\n",
    "dataframes_dict = {}\n",
    "\n",
    "# Iterate through all files in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith(\".bvh\"):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        \n",
    "        \n",
    "        # Open the BVH file for reading\n",
    "        with open(file_path, 'r') as file:\n",
    "            # Set a counter variable to keep track of the current line number\n",
    "            line_number = 0\n",
    "            data = []\n",
    "\n",
    "            # Iterate over each line in the file\n",
    "            for line in file:\n",
    "                # Increment the line number\n",
    "                line_number += 1\n",
    "\n",
    "                # Check if the current line number is greater than or equal to 353\n",
    "                if line_number >= 353:\n",
    "                    # Split the line into a list of values\n",
    "                    values = line.split()\n",
    "                    data.append(values)\n",
    "\n",
    "        # Read the bvh file into a DataFrame,\n",
    "        skeleton = pd.DataFrame(data, columns=joints)\n",
    "\n",
    "        # Rename the DataFrame based on the file name\n",
    "        skeleton_name = f\"{filename.split('.')[0]}\"\n",
    "\n",
    "        # Store the DataFrame in the dictionary\n",
    "        dataframes_dict[skeleton_name] = skeleton\n",
    "        print(skeleton_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb82ec3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataframes_dict[list(dataframes_dict.keys())[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d9fd02",
   "metadata": {},
   "source": [
    "Get only joint positions (_xp, _yp, _zp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5442d4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns you want in the new DataFrame\n",
    "\n",
    "# Store column names that end with '_Xp', '_Yp', '_Zp' in a list\n",
    "selected_columns = [col for col in data.columns if col.endswith('_xp') or col.endswith('_yp') or col.endswith('_zp')]\n",
    "\n",
    "# Iterate through the original dictionary and create new DataFrames with selected columns\n",
    "for key, df in dataframes_dict.items():\n",
    "    dataframes_dict[key] = df[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73aa1d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hips_xp              False\n",
       "Hips_yp              False\n",
       "Hips_zp              False\n",
       "RightUpLeg_xp        False\n",
       "RightUpLeg_yp        False\n",
       "                     ...  \n",
       "LeftHandPinky2_yp    False\n",
       "LeftHandPinky2_zp    False\n",
       "LeftHandPinky3_xp    False\n",
       "LeftHandPinky3_yp    False\n",
       "LeftHandPinky3_zp    False\n",
       "Length: 177, dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display one of the selected DataFrames\n",
    "dataframes_dict[list(dataframes_dict.keys())[0]].isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9849b31f",
   "metadata": {},
   "source": [
    "# Define resolution (30fps)\n",
    "Default resolution is 120 fps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c02e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "step = 4 # for 30fps: default 119fps \n",
    "\n",
    "# Define a function to create the new dataframe\n",
    "def create_new_dataframe(old_df, interval):\n",
    "    new_data = []\n",
    "    for i in range(0, len(old_df), interval):\n",
    "        # Take the last row in each interval\n",
    "        new_data.append(old_df.iloc[i:i+interval].iloc[-1])\n",
    "    # Create a new dataframe from the collected data\n",
    "    new_dataframe = pd.DataFrame(new_data)\n",
    "    return new_dataframe\n",
    "\n",
    "# Iterate through the original dictionary and create new filtered DataFrames\n",
    "for key, df in dataframes_dict.items():\n",
    "    # Create the new dataframe\n",
    "    dataframes_dict[key] = create_new_dataframe(df, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d552594",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataframes_dict[list(dataframes_dict.keys())[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae04412",
   "metadata": {},
   "source": [
    "# Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d29330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create a MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Iterate through each DataFrame in the dictionary and normalize it\n",
    "normalized_dataframes_dict = {}\n",
    "for key, df in dataframes_dict.items():\n",
    "    for col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        \n",
    "    # Select only numeric columns for normalization\n",
    "    numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    \n",
    "    # Normalize the numeric columns using MinMaxScaler\n",
    "    df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "\n",
    "    # Store the normalized DataFrame in the new dictionary\n",
    "    dataframes_dict[key] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d642268f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_dict[list(dataframes_dict.keys())[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42afabcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataframes_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9087f30",
   "metadata": {},
   "source": [
    "# Save the data into npy and csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cdb3f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 fps InHARD 13 features: \n",
      "(15627, 63)\n",
      "(13113, 63)\n",
      "(12561, 63)\n",
      "(12623, 63)\n",
      "(10404, 63)\n",
      "(18822, 63)\n",
      "(11757, 63)\n",
      "(12397, 63)\n",
      "(18724, 63)\n",
      "(13731, 63)\n",
      "(24193, 63)\n",
      "(16898, 63)\n",
      "(15170, 63)\n",
      "(12308, 63)\n",
      "(26342, 63)\n",
      "(10379, 63)\n",
      "(9781, 63)\n",
      "(13082, 63)\n",
      "(10767, 63)\n",
      "(8765, 63)\n",
      "(8422, 63)\n",
      "(8363, 63)\n",
      "(7361, 63)\n",
      "(7377, 63)\n",
      "(14914, 63)\n",
      "(11222, 63)\n",
      "(10219, 63)\n",
      "(16405, 63)\n",
      "(13165, 63)\n",
      "(14589, 63)\n",
      "(11118, 63)\n",
      "(13689, 63)\n",
      "(9737, 63)\n",
      "(7949, 63)\n",
      "(10342, 63)\n",
      "(8669, 63)\n",
      "(19329, 63)\n",
      "(12052, 63)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a directory to store the npy files (optional)\n",
    "output_directory = 'npy_30fps_p_59'\n",
    "output_csv_directory = 'csv_30fps_p_59'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(output_csv_directory):\n",
    "    os.makedirs(output_csv_directory)\n",
    "\n",
    "print('30 fps InHARD 13 features: ')\n",
    "for key, df in dataframes_dict.items():\n",
    "    \n",
    "    # Save the normalized DataFrame as a CSV file\n",
    "    output_filepath = os.path.join(output_csv_directory, f\"{key}.csv\")\n",
    "    df.to_csv(output_filepath, index=False)\n",
    "\n",
    "    # Save the normalized DataFrame as a .npy file\n",
    "    output_filepath = os.path.join(output_directory, f\"{key}.npy\")\n",
    "    np.save(output_filepath, df.to_numpy())\n",
    "    \n",
    "    d=np.load(output_filepath)\n",
    "    print(d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f62bb888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15627, 63)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=np.load('npy_30fps_p_21/P01_R01.npy')\n",
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a971eb35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
